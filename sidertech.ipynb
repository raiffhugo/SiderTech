{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04f975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes\n",
    "import os\n",
    "import sqlite3\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce50ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar vari√°veis de ambiente\n",
    "load_dotenv()\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db46699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar ao banco de dados\n",
    "DB_PATH = \"manutencao_industrial.db\"\n",
    "conn = sqlite3.connect(DB_PATH, check_same_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea2f5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar modelo da DeepSeek\n",
    "llm = ChatDeepSeek(api_key=DEEPSEEK_API_KEY, model=\"deepseek-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cca772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fun√ß√µes Auxiliares ---\n",
    "def get_db_schema(connection):\n",
    "    \"\"\"Extrai o schema de todas as tabelas do banco de dados SQLite.\"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';\")\n",
    "    tables = cursor.fetchall()\n",
    "    schema_str = \"\"\n",
    "    for table_name in tables:\n",
    "        table_name = table_name[0]\n",
    "        cursor.execute(f\"SELECT sql FROM sqlite_master WHERE name = '{table_name}';\")\n",
    "        create_table_stmt = cursor.fetchone()[0]\n",
    "        schema_str += f\"{create_table_stmt};\\n\\n\"\n",
    "    return schema_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4552d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega o schema uma vez para ser usado nos prompts\n",
    "db_schema = get_db_schema(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e8e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Defini√ß√£o do Estado do Grafo ---\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    chat_history: list[HumanMessage | AIMessage]\n",
    "    sql_query: str\n",
    "    sql_result: str | List[dict] # Pode ser uma string de erro ou lista de resultados\n",
    "    final_answer: str\n",
    "    error_count: int # Para evitar loops infinitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11a2a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- N√≥s do Grafo (Fun√ß√µes) ---\n",
    "def generate_sql(state: AgentState) -> AgentState:\n",
    "    \"\"\"Gera uma consulta SQL a partir da pergunta do usu√°rio, usando o hist√≥rico.\"\"\"\n",
    "\n",
    "    # Formatando o hist√≥rico para ser leg√≠vel no prompt\n",
    "    history_str = \"\\n\".join([f\"{'Humano' if isinstance(m, HumanMessage) else 'Assistente'}: {m.content}\" for m in state['chat_history']])\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Voc√™ √© um assistente especialista em bancos de dados SQLite, atuando no contexto de uma planta industrial da SiderTech Solutions, no setor metalmec√¢nico. \n",
    "\n",
    "        Sua tarefa √© gerar uma consulta SQL precisa com base na pergunta de um usu√°rio (que pode ser um operador, engenheiro ou gestor), usando o schema fornecido e, se necess√°rio, o hist√≥rico da conversa para obter contexto.\n",
    "\n",
    "        Importante:\n",
    "        - Gere apenas a consulta SQL (sem explica√ß√µes, coment√°rios ou rodeios).\n",
    "        - Nunca use aspas para nomes de tabelas ou colunas.\n",
    "        - Se n√£o for poss√≠vel responder com os dados dispon√≠veis, retorne exatamente: `SEM_RESPOSTA`\n",
    "        - Utilize apenas comandos SELECT.\n",
    "        - Seja cuidadoso com relacionamentos entre tabelas e selecione apenas o que for necess√°rio.\n",
    "        - Adapte a consulta ao contexto de manuten√ß√£o industrial (equipamentos, ordens de servi√ßo, t√©cnicos, turnos, hist√≥rico etc).\n",
    "\n",
    "        -- Hist√≥rico da Conversa --\n",
    "        {chat_history}\n",
    "        -- Fim do Hist√≥rico --\n",
    "\n",
    "        -- Schema do Banco de Dados --\n",
    "        {schema}\n",
    "        -- Fim do Schema --\n",
    "\n",
    "        Pergunta atual do usu√°rio:\n",
    "        {question}\n",
    "\n",
    "        Consulta SQL:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    sql_query = chain.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"schema\": db_schema,\n",
    "        \"chat_history\": history_str\n",
    "    })\n",
    "    \n",
    "    return {**state, \"sql_query\": sql_query.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9947e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(state: AgentState) -> AgentState:\n",
    "    \"\"\"Executa a consulta SQL e retorna o resultado ou um erro.\"\"\"\n",
    "    sql = state[\"sql_query\"]\n",
    "\n",
    "    # Medida de seguran√ßa simples: permitir apenas SELECT\n",
    "    if not sql.strip().upper().startswith(\"SELECT\"):\n",
    "        return {**state, \"sql_result\": \"Erro de Seguran√ßa: Apenas consultas SELECT s√£o permitidas.\"}\n",
    "\n",
    "    try:\n",
    "        cursor = conn.execute(sql)\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "        result = [dict(zip(columns, row)) for row in rows]\n",
    "        if not result:\n",
    "            result = \"A consulta n√£o retornou resultados.\"\n",
    "        return {**state, \"sql_result\": result}\n",
    "    except Exception as e:\n",
    "        return {**state, \"sql_result\": f\"Erro SQL: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b00b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_answer(state: AgentState) -> AgentState:\n",
    "    \"\"\"Gera uma resposta em linguagem natural com base nos resultados.\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Voc√™ √© um assistente inteligente e prestativo, projetado para apoiar operadores, engenheiros e gestores da SiderTech Solutions no acesso f√°cil e r√°pido a dados de manuten√ß√£o industrial.\n",
    "\n",
    "        Sua tarefa √© interpretar perguntas feitas em linguagem natural e responder com base nos resultados de uma consulta SQL, utilizando uma linguagem clara, objetiva e adequada ao ambiente de f√°brica.\n",
    "\n",
    "        - Se os dados retornarem vazios ou houver erro na consulta, explique isso de forma amig√°vel, sem termos t√©cnicos complexos.\n",
    "        - Sempre seja direto e evite rodeios.\n",
    "        - Foque em entregar uma resposta √∫til e f√°cil de entender para quem est√° na opera√ß√£o.\n",
    "\n",
    "        Pergunta Original:\n",
    "        {question}\n",
    "\n",
    "        Resultados da Consulta SQL:\n",
    "        {sql_result}\n",
    "\n",
    "        Resposta Final (em portugu√™s do Brasil):\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    final_answer = chain.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"sql_result\": state[\"sql_result\"]\n",
    "    })\n",
    "    \n",
    "    return {**state, \"final_answer\": final_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a963a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- L√≥gica Condicional do Grafo ---\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Decide o pr√≥ximo passo: gerar resposta, tentar novamente ou parar.\"\"\"\n",
    "    if isinstance(state[\"sql_result\"], str) and \"Erro\" in state[\"sql_result\"]:\n",
    "        # Se houve um erro, incrementa o contador e tenta de novo (se n√£o excedeu o limite)\n",
    "        error_count = state.get(\"error_count\", 0) + 1\n",
    "        if error_count >= 2: # Tenta corrigir no m√°ximo 1 vez\n",
    "            return \"end_with_error\"\n",
    "        else:\n",
    "            return \"retry_sql_generation\"\n",
    "    else:\n",
    "        return \"generate_answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45adaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constru√ß√£o do Grafo com LangGraph ---\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"generate_sql\", generate_sql)\n",
    "builder.add_node(\"execute_sql\", execute_sql)\n",
    "builder.add_node(\"generate_final_answer\", generate_final_answer)\n",
    "\n",
    "builder.set_entry_point(\"generate_sql\")\n",
    "\n",
    "# Adiciona a l√≥gica condicional\n",
    "builder.add_conditional_edges(\n",
    "    \"execute_sql\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"retry_sql_generation\": \"generate_sql\",\n",
    "        \"generate_answer\": \"generate_final_answer\",\n",
    "        \"end_with_error\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"generate_sql\", \"execute_sql\")\n",
    "builder.add_edge(\"generate_final_answer\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730b2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hist√≥rico de conversa (inicialmente vazio)\n",
    "chat_history = []\n",
    "\n",
    "# Fun√ß√£o para interagir com o agente\n",
    "def chat_with_agent(question):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para conversar com o agente industrial.\n",
    "    Recebe uma pergunta em linguagem natural, mostra a resposta,\n",
    "    o SQL gerado e o resultado da consulta.\n",
    "    \"\"\"\n",
    "\n",
    "    # Adiciona pergunta ao hist√≥rico\n",
    "    chat_history.append(HumanMessage(content=question))\n",
    "\n",
    "    # Prepara o estado inicial do grafo\n",
    "    initial_state = {\n",
    "        \"question\": question,\n",
    "        \"chat_history\": chat_history[:-1],  # hist√≥rico at√© a pergunta atual\n",
    "        \"error_count\": 0\n",
    "    }\n",
    "\n",
    "    # Executa o agente\n",
    "    final_state = graph.invoke(initial_state)\n",
    "\n",
    "    # Extrai resposta\n",
    "    final_answer = final_state.get(\"final_answer\", \"O agente n√£o conseguiu concluir a tarefa.\")\n",
    "    # sql_query = final_state.get(\"sql_query\", \"N/A\")\n",
    "    # sql_result = final_state.get(\"sql_result\", \"N/A\")\n",
    "\n",
    "    # Adiciona resposta do agente ao hist√≥rico\n",
    "    chat_history.append(AIMessage(content=final_answer))\n",
    "\n",
    "    # Exibe no notebook\n",
    "    print(\"\\nü§ñ Resposta do Agente:\\n\")\n",
    "    print(final_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d8acdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Resposta do Agente:\n",
      "\n",
      "Nos √∫ltimos 3 meses, foram realizadas manuten√ß√µes nos seguintes tipos de equipamentos:  \n",
      "\n",
      "- Caldeira  \n",
      "- Bomba  \n",
      "- Motor  \n",
      "- Compressor\n"
     ]
    }
   ],
   "source": [
    "chat_with_agent(\"Quais os tipos de equipamentos que tiveram manuten√ß√£o nos √∫ltimos 3 meses?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d879fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Resposta do Agente:\n",
      "\n",
      "O t√©cnico que trabalhou em mais ordens de manuten√ß√£o √© o **Tecnico 3**.\n"
     ]
    }
   ],
   "source": [
    "chat_with_agent(\"Qual o nome do t√©cnico que trabalhou em mais ordens de manuten√ß√£o?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b32d0951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Resposta do Agente:\n",
      "\n",
      "O t√©cnico que trabalhou na ordem 32 foi o **Tecnico 3**.\n"
     ]
    }
   ],
   "source": [
    "chat_with_agent(\"Qual t√©cnico trabalhou na ordem 32?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6c70708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Resposta do Agente:\n",
      "\n",
      "A especialidade dele √© el√©trica.\n"
     ]
    }
   ],
   "source": [
    "chat_with_agent(\"Qual a especialidade dele?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
